{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DweYe9FcbMK_"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# Load CSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ap_W4aQcgNT"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/csv\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-3Xbt0FfGfs"
   },
   "source": [
    "This tutorial provides examples of how to use CSV data with TensorFlow.\n",
    "\n",
    "There are two main parts to this:\n",
    "\n",
    "1. **Loading the data off disk**\n",
    "2. **Pre-processing it into a form suitable for training.**\n",
    "\n",
    "This tutorial focuses on the loading, and gives some quick examples of preprocessing. To learn more about the preprocessing aspect, check out the [Working with preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) guide and the [Classify structured data using Keras preprocessing layers](../structured_data/preprocessing_layers.ipynb) tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgZ9gjmPfSnK"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:18.689888Z",
     "iopub.status.busy": "2022-06-17T01:24:18.689378Z",
     "iopub.status.idle": "2022-06-17T01:24:20.535630Z",
     "shell.execute_reply": "2022-06-17T01:24:20.534511Z"
    },
    "id": "baYFZMW_bJHh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wuqj601Qw0Ml"
   },
   "source": [
    "## Mixed data types\n",
    "\n",
    "The \"Titanic\" dataset contains information about the passengers on the Titanic. The nominal task on this dataset is to predict who survived.\n",
    "\n",
    "![The Titanic](images/csv/Titanic.jpg)\n",
    "\n",
    "Image [from Wikimedia](https://commons.wikimedia.org/wiki/File:RMS_Titanic_3.jpg)\n",
    "\n",
    "The raw data can easily be loaded as a Pandas `DataFrame`, but is not immediately usable as input to a TensorFlow model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:29.910021Z",
     "iopub.status.busy": "2022-06-17T01:24:29.909788Z",
     "iopub.status.idle": "2022-06-17T01:24:29.973757Z",
     "shell.execute_reply": "2022-06-17T01:24:29.973088Z"
    },
    "id": "GS-dBMpuYMnz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>17/10/2014</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>27/06/2006</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197</td>\n",
       "      <td>22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>06/09/2000</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413</td>\n",
       "      <td>14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>25/05/1990</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415</td>\n",
       "      <td>74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>06/06/2014</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583</td>\n",
       "      <td>91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     months_as_customer     age policy_number policy_bind_date policy_state  \\\n",
       "328                  48  521585    17/10/2014               OH      250/500   \n",
       "228                  42  342868    27/06/2006               IN      250/500   \n",
       "134                  29  687698    06/09/2000               OH      100/300   \n",
       "256                  41  227811    25/05/1990               IL      250/500   \n",
       "228                  44  367455    06/06/2014               IL     500/1000   \n",
       "\n",
       "     policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "328        1000               1406                     91               0   \n",
       "228        2000               1197                     22         5000000   \n",
       "134        2000               1413                     14         5000000   \n",
       "256        2000               1415                     74         6000000   \n",
       "228        1000               1583                     91         6000000   \n",
       "\n",
       "    insured_zip  ... witnesses police_report_available total_claim_amount  \\\n",
       "328      466132  ...         2                     YES              71610   \n",
       "228      468176  ...         0                       ?               5070   \n",
       "134      430632  ...         3                      NO              34650   \n",
       "256      608117  ...         2                      NO              63400   \n",
       "228      610706  ...         1                      NO               6500   \n",
       "\n",
       "    injury_claim property_claim  vehicle_claim  auto_make auto_model  \\\n",
       "328         6510          13020          52080       Saab        92x   \n",
       "228          780            780           3510   Mercedes       E400   \n",
       "134         7700           3850          23100      Dodge        RAM   \n",
       "256         6340           6340          50720  Chevrolet      Tahoe   \n",
       "228         1300            650           4550     Accura        RSX   \n",
       "\n",
       "    auto_year fraud_reported  \n",
       "328      2004            1.0  \n",
       "228      2007            1.0  \n",
       "134      2007            0.0  \n",
       "256      2014            1.0  \n",
       "228      2009            0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"insurance_claims_v2.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:29.976719Z",
     "iopub.status.busy": "2022-06-17T01:24:29.976488Z",
     "iopub.status.idle": "2022-06-17T01:24:29.980060Z",
     "shell.execute_reply": "2022-06-17T01:24:29.979508Z"
    },
    "id": "D8rCGIK1ZzKx"
   },
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('fraud_reported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urHOwpCDYtcI"
   },
   "source": [
    "Because of the different data types and ranges, you can't simply stack the features into a NumPy array and pass it to a `tf.keras.Sequential` model. Each column needs to be handled individually.\n",
    "\n",
    "As one option, you could preprocess your data offline (using any tool you like) to convert categorical columns to numeric columns, then pass the processed output to your TensorFlow model. The disadvantage to that approach is that if you save and export your model the preprocessing is not saved with it. The Keras preprocessing layers avoid this problem because they're part of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bta4Sx0Zau5v"
   },
   "source": [
    "In this example, you'll build a model that implements the preprocessing logic using [Keras functional API](https://www.tensorflow.org/guide/keras/functional). You could also do it by [subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n",
    "\n",
    "The functional API operates on \"symbolic\" tensors. Normal \"eager\" tensors have a value. In contrast these \"symbolic\" tensors do not. Instead they keep track of which operations are run on them, and build a representation of the calculation, that you can run later. Here's a quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:29.983515Z",
     "iopub.status.busy": "2022-06-17T01:24:29.983167Z",
     "iopub.status.idle": "2022-06-17T01:24:29.996651Z",
     "shell.execute_reply": "2022-06-17T01:24:29.996125Z"
    },
    "id": "730F16_97D-3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None,) dtype=float32 (created by layer 'tf.__operators__.add')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Perform a calculation using the input\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:29.999409Z",
     "iopub.status.busy": "2022-06-17T01:24:29.999187Z",
     "iopub.status.idle": "2022-06-17T01:24:30.004569Z",
     "shell.execute_reply": "2022-06-17T01:24:30.004021Z"
    },
    "id": "RtcNXWB18kMJ"
   },
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.007340Z",
     "iopub.status.busy": "2022-06-17T01:24:30.007118Z",
     "iopub.status.idle": "2022-06-17T01:24:30.012915Z",
     "shell.execute_reply": "2022-06-17T01:24:30.012252Z"
    },
    "id": "fUGQOUqZ8sa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(calc(1).numpy())\n",
    "print(calc(2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNS9lT7f6_U2"
   },
   "source": [
    "To build the preprocessing model, start by building a set of symbolic `tf.keras.Input` objects, matching the names and data-types of the CSV columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.015619Z",
     "iopub.status.busy": "2022-06-17T01:24:30.015386Z",
     "iopub.status.idle": "2022-06-17T01:24:30.027117Z",
     "shell.execute_reply": "2022-06-17T01:24:30.026576Z"
    },
    "id": "5WODe_1da3yw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'months_as_customer': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'months_as_customer')>,\n",
       " 'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'policy_number': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'policy_number')>,\n",
       " 'policy_bind_date': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'policy_bind_date')>,\n",
       " 'policy_state': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'policy_state')>,\n",
       " 'policy_csl': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'policy_csl')>,\n",
       " 'policy_deductable': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'policy_deductable')>,\n",
       " 'policy_annual_premium': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'policy_annual_premium')>,\n",
       " 'umbrella_limit': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'umbrella_limit')>,\n",
       " 'insured_zip': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'insured_zip')>,\n",
       " 'insured_sex': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'insured_sex')>,\n",
       " 'insured_education_level': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'insured_education_level')>,\n",
       " 'insured_occupation': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'insured_occupation')>,\n",
       " 'insured_hobbies': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'insured_hobbies')>,\n",
       " 'insured_relationship': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'insured_relationship')>,\n",
       " 'capital-gains': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'capital-gains')>,\n",
       " 'capital-loss': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'capital-loss')>,\n",
       " 'incident_date': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'incident_date')>,\n",
       " 'incident_type': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'incident_type')>,\n",
       " 'collision_type': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'collision_type')>,\n",
       " 'incident_severity': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'incident_severity')>,\n",
       " 'authorities_contacted': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'authorities_contacted')>,\n",
       " 'incident_state': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'incident_state')>,\n",
       " 'incident_city': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'incident_city')>,\n",
       " 'incident_location': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'incident_location')>,\n",
       " 'incident_hour_of_the_day': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'incident_hour_of_the_day')>,\n",
       " 'number_of_vehicles_involved': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'number_of_vehicles_involved')>,\n",
       " 'property_damage': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'property_damage')>,\n",
       " 'bodily_injuries': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'bodily_injuries')>,\n",
       " 'witnesses': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'witnesses')>,\n",
       " 'police_report_available': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'police_report_available')>,\n",
       " 'total_claim_amount': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'total_claim_amount')>,\n",
       " 'injury_claim': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'injury_claim')>,\n",
       " 'property_claim': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'property_claim')>,\n",
       " 'vehicle_claim': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'vehicle_claim')>,\n",
       " 'auto_make': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'auto_make')>,\n",
       " 'auto_model': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'auto_model')>,\n",
       " 'auto_year': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'auto_year')>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaheJFmymq8l"
   },
   "source": [
    "The first step in your preprocessing logic is to concatenate the numeric inputs together, and run them through a normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.029851Z",
     "iopub.status.busy": "2022-06-17T01:24:30.029634Z",
     "iopub.status.idle": "2022-06-17T01:24:30.205853Z",
     "shell.execute_reply": "2022-06-17T01:24:30.205168Z"
    },
    "id": "wPRC_E6rkp8D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 13) dtype=float32 (created by layer 'normalization')>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JoR45Uj712l"
   },
   "source": [
    "Collect all the symbolic preprocessing results, to concatenate them later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.209272Z",
     "iopub.status.busy": "2022-06-17T01:24:30.209037Z",
     "iopub.status.idle": "2022-06-17T01:24:30.212195Z",
     "shell.execute_reply": "2022-06-17T01:24:30.211594Z"
    },
    "id": "M7jIJw5XntdN"
   },
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0Hryylyosfm"
   },
   "source": [
    "For the string inputs use the `tf.keras.layers.StringLookup` function to map from strings to integer indices in a vocabulary. Next, use `tf.keras.layers.CategoryEncoding` to convert the indexes into `float32` data appropriate for the model.\n",
    "\n",
    "The default settings for the `tf.keras.layers.CategoryEncoding` layer create a one-hot vector for each input. A `tf.keras.layers.Embedding` would also work. Check out the [Working with preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) guide and the [Classify structured data using Keras preprocessing layers](../structured_data/preprocessing_layers.ipynb) tutorial for more on this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.215363Z",
     "iopub.status.busy": "2022-06-17T01:24:30.215128Z",
     "iopub.status.idle": "2022-06-17T01:24:30.314405Z",
     "shell.execute_reply": "2022-06-17T01:24:30.313830Z"
    },
    "id": "79fi1Cgan2YV"
   },
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "  \n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnhv0T7itnc7"
   },
   "source": [
    "With the collection of `inputs` and `preprocessed_inputs`, you can concatenate all the preprocessed inputs together, and build a model that handles the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.317753Z",
     "iopub.status.busy": "2022-06-17T01:24:30.317506Z",
     "iopub.status.idle": "2022-06-17T01:24:30.375850Z",
     "shell.execute_reply": "2022-06-17T01:24:30.375122Z"
    },
    "id": "XJRzUTe8ukXc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNHxrNW8vdda"
   },
   "source": [
    "This model just contains the input preprocessing. You can run it to see what it does to your data. Keras models don't automatically convert pandas `DataFrame`s because it's not clear if it should be converted to one tensor or to a dictionary of tensors. So, convert it to a dictionary of tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.379188Z",
     "iopub.status.busy": "2022-06-17T01:24:30.378946Z",
     "iopub.status.idle": "2022-06-17T01:24:30.383223Z",
     "shell.execute_reply": "2022-06-17T01:24:30.382636Z"
    },
    "id": "5YjdYyMEacwQ"
   },
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nKJYoPByada"
   },
   "source": [
    "Slice out the first training example and pass it to this preprocessing model, you see the numeric features and string one-hots all concatenated together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.386055Z",
     "iopub.status.busy": "2022-06-17T01:24:30.385846Z",
     "iopub.status.idle": "2022-06-17T01:24:30.410401Z",
     "shell.execute_reply": "2022-06-17T01:24:30.409888Z"
    },
    "id": "SjnmU8PSv8T3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4379), dtype=float32, numpy=\n",
       "array([[ 0.991, -0.096, -0.222, ...,  0.   ,  0.   ,  0.   ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkBf4LvmzMDp"
   },
   "source": [
    "Now, build the model on top of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.413549Z",
     "iopub.status.busy": "2022-06-17T01:24:30.413314Z",
     "iopub.status.idle": "2022-06-17T01:24:30.531185Z",
     "shell.execute_reply": "2022-06-17T01:24:30.530528Z"
    },
    "id": "coIPtGaCzUV7"
   },
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK5uBQQF2KbZ"
   },
   "source": [
    "When you train the model, pass the dictionary of features as `x`, and the label as `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:30.534982Z",
     "iopub.status.busy": "2022-06-17T01:24:30.534495Z",
     "iopub.status.idle": "2022-06-17T01:24:31.983087Z",
     "shell.execute_reply": "2022-06-17T01:24:31.982231Z"
    },
    "id": "D1gVfwJ61ejz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 2s 5ms/step - loss: nan\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dc405d0460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxgJarZk3bfH"
   },
   "source": [
    "Since the preprocessing is part of the model, you can save the model and reload it somewhere else and get identical results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:31.986722Z",
     "iopub.status.busy": "2022-06-17T01:24:31.986169Z",
     "iopub.status.idle": "2022-06-17T01:24:35.180039Z",
     "shell.execute_reply": "2022-06-17T01:24:35.179377Z"
    },
    "id": "Ay-8ymNA2ZCh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) capital-gains, capital-loss with unsupported characters which will be renamed to capital_gains, capital_loss in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    }
   ],
   "source": [
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:35.187084Z",
     "iopub.status.busy": "2022-06-17T01:24:35.186826Z",
     "iopub.status.idle": "2022-06-17T01:24:35.221125Z",
     "shell.execute_reply": "2022-06-17T01:24:35.220421Z"
    },
    "id": "Qm6jMTpD20lK"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DPERALES\\OneDrive\\UST Global\\ITACA\\AI\\Tensorflow\\Beginners\\load csv claims.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/load%20csv%20claims.ipynb#Y111sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m before \u001b[39m=\u001b[39m titanic_model(features_dict)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/load%20csv%20claims.ipynb#Y111sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m after \u001b[39m=\u001b[39m reloaded(features_dict)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/load%20csv%20claims.ipynb#Y111sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39massert\u001b[39;00m (before\u001b[39m-\u001b[39mafter)\u001b[39m<\u001b[39m\u001b[39m1e-3\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/load%20csv%20claims.ipynb#Y111sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(before)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/load%20csv%20claims.ipynb#Y111sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(after)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VsPlxIRZpXf"
   },
   "source": [
    "## Using tf.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyVDCwGzR5HW"
   },
   "source": [
    "In the previous section you relied on the model's built-in data shuffling and batching while training the model.\n",
    "\n",
    "If you need more control over the input data pipeline or need to use data that doesn't easily fit into memory: use `tf.data`.\n",
    "\n",
    "For more examples, refer to the [`tf.data`: Build TensorFlow input pipelines](../../guide/data.ipynb) guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP5Y1jM2Sor0"
   },
   "source": [
    "### On in memory data\n",
    "\n",
    "As a first example of applying `tf.data` to CSV data, consider the following code to manually slice up the dictionary of features from the previous section. For each index, it takes that index for each feature:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:35.224657Z",
     "iopub.status.busy": "2022-06-17T01:24:35.224239Z",
     "iopub.status.idle": "2022-06-17T01:24:35.228074Z",
     "shell.execute_reply": "2022-06-17T01:24:35.227311Z"
    },
    "id": "i8wE-MVuVu7_"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "  for i in itertools.count():\n",
    "    # For each feature take index `i`\n",
    "    example = {name:values[i] for name, values in features.items()}\n",
    "    yield example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ3RTbS9YEal"
   },
   "source": [
    "Run this and print the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:35.231142Z",
     "iopub.status.busy": "2022-06-17T01:24:35.230751Z",
     "iopub.status.idle": "2022-06-17T01:24:35.235257Z",
     "shell.execute_reply": "2022-06-17T01:24:35.234537Z"
    },
    "id": "Wwq8XK88WwFk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "months_as_customer : 48\n",
      "age                : 521585\n",
      "policy_number      : 17/10/2014\n",
      "policy_bind_date   : OH\n",
      "policy_state       : 250/500\n",
      "policy_csl         : 1000\n",
      "policy_deductable  : 1406\n",
      "policy_annual_premium: 91\n",
      "umbrella_limit     : 0\n",
      "insured_zip        : 466132\n",
      "insured_sex        : MALE\n",
      "insured_education_level: MD\n",
      "insured_occupation : craft-repair\n",
      "insured_hobbies    : sleeping\n",
      "insured_relationship: husband\n",
      "capital-gains      : 53300\n",
      "capital-loss       : 0\n",
      "incident_date      : 25/01/2015\n",
      "incident_type      : Single Vehicle Collision\n",
      "collision_type     : Side Collision\n",
      "incident_severity  : Major Damage\n",
      "authorities_contacted: Police\n",
      "incident_state     : SC\n",
      "incident_city      : Columbus\n",
      "incident_location  : 9935 4th Drive\n",
      "incident_hour_of_the_day: 5\n",
      "number_of_vehicles_involved: 1\n",
      "property_damage    : YES\n",
      "bodily_injuries    : 1\n",
      "witnesses          : 2\n",
      "police_report_available: YES\n",
      "total_claim_amount : 71610\n",
      "injury_claim       : 6510\n",
      "property_claim     : 13020\n",
      "vehicle_claim      : 52080\n",
      "auto_make          : Saab\n",
      "auto_model         : 92x\n",
      "auto_year          : 2004\n"
     ]
    }
   ],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvp8Dct6YOIE"
   },
   "source": [
    "The most basic `tf.data.Dataset` in memory data loader is the `Dataset.from_tensor_slices` constructor. This returns a `tf.data.Dataset` that implements a generalized version of the above `slices` function, in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:35.238080Z",
     "iopub.status.busy": "2022-06-17T01:24:35.237863Z",
     "iopub.status.idle": "2022-06-17T01:24:35.242990Z",
     "shell.execute_reply": "2022-06-17T01:24:35.242192Z"
    },
    "id": "2gEJthslYxeV"
   },
   "outputs": [],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZC0rTpMZMZK"
   },
   "source": [
    "You can iterate over a `tf.data.Dataset` like any other python iterable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:35.245863Z",
     "iopub.status.busy": "2022-06-17T01:24:35.245653Z",
     "iopub.status.idle": "2022-06-17T01:24:35.254618Z",
     "shell.execute_reply": "2022-06-17T01:24:35.253976Z"
    },
    "id": "gOHbiefaY4ag"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "months_as_customer : 48\n",
      "age                : 521585\n",
      "policy_number      : b'17/10/2014'\n",
      "policy_bind_date   : b'OH'\n",
      "policy_state       : b'250/500'\n",
      "policy_csl         : 1000\n",
      "policy_deductable  : 1406\n",
      "policy_annual_premium: 91\n",
      "umbrella_limit     : 0\n",
      "insured_zip        : b'466132'\n",
      "insured_sex        : b'MALE'\n",
      "insured_education_level: b'MD'\n",
      "insured_occupation : b'craft-repair'\n",
      "insured_hobbies    : b'sleeping'\n",
      "insured_relationship: b'husband'\n",
      "capital-gains      : 53300\n",
      "capital-loss       : b'0'\n",
      "incident_date      : b'25/01/2015'\n",
      "incident_type      : b'Single Vehicle Collision'\n",
      "collision_type     : b'Side Collision'\n",
      "incident_severity  : b'Major Damage'\n",
      "authorities_contacted: b'Police'\n",
      "incident_state     : b'SC'\n",
      "incident_city      : b'Columbus'\n",
      "incident_location  : b'9935 4th Drive'\n",
      "incident_hour_of_the_day: 5\n",
      "number_of_vehicles_involved: b'1'\n",
      "property_damage    : b'YES'\n",
      "bodily_injuries    : 1\n",
      "witnesses          : b'2'\n",
      "police_report_available: b'YES'\n",
      "total_claim_amount : 71610\n",
      "injury_claim       : 6510\n",
      "property_claim     : 13020\n",
      "vehicle_claim      : b'52080'\n",
      "auto_make          : b'Saab'\n",
      "auto_model         : b'92x'\n",
      "auto_year          : 2004\n"
     ]
    }
   ],
   "source": [
    "for example in features_ds:\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwcFoVJWZY5F"
   },
   "source": [
    "The `from_tensor_slices` function can handle any structure of nested dictionaries or tuples. The following code makes a dataset of `(features_dict, labels)` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:35.257563Z",
     "iopub.status.busy": "2022-06-17T01:24:35.257152Z",
     "iopub.status.idle": "2022-06-17T01:24:35.263953Z",
     "shell.execute_reply": "2022-06-17T01:24:35.263249Z"
    },
    "id": "xIHGBy76Zcrx"
   },
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQwxitt8c2GK"
   },
   "source": [
    "To train a model using this `Dataset`, you'll need to at least `shuffle` and `batch` the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:35.267022Z",
     "iopub.status.busy": "2022-06-17T01:24:35.266467Z",
     "iopub.status.idle": "2022-06-17T01:24:35.271576Z",
     "shell.execute_reply": "2022-06-17T01:24:35.270857Z"
    },
    "id": "SbJcbldhddeC"
   },
   "outputs": [],
   "source": [
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4FRqhRFuoJx"
   },
   "source": [
    "Instead of passing `features` and `labels` to `Model.fit`, you pass the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:35.274865Z",
     "iopub.status.busy": "2022-06-17T01:24:35.274609Z",
     "iopub.status.idle": "2022-06-17T01:24:36.073668Z",
     "shell.execute_reply": "2022-06-17T01:24:36.072971Z"
    },
    "id": "8yXkNPumdBtB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 5ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dc4188e1f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXuibiv9exT7"
   },
   "source": [
    "### From a single file\n",
    "\n",
    "So far this tutorial has worked with in-memory data. `tf.data` is a highly scalable toolkit for building data pipelines, and provides a few functions for dealing loading CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:36.077289Z",
     "iopub.status.busy": "2022-06-17T01:24:36.076727Z",
     "iopub.status.idle": "2022-06-17T01:24:36.088982Z",
     "shell.execute_reply": "2022-06-17T01:24:36.088407Z"
    },
    "id": "Ncf5t6tgL5ZI"
   },
   "outputs": [],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4N-plO4tDXd"
   },
   "source": [
    "Now read the CSV data from the file and create a `tf.data.Dataset`.\n",
    "\n",
    "(For the full documentation, see `tf.data.experimental.make_csv_dataset`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:36.092318Z",
     "iopub.status.busy": "2022-06-17T01:24:36.091773Z",
     "iopub.status.idle": "2022-06-17T01:24:36.135662Z",
     "shell.execute_reply": "2022-06-17T01:24:36.135067Z"
    },
    "id": "yIbUscB9sqha"
   },
   "outputs": [],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    \"insurance_claims.csv\",\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='fraud_reported',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf3v3BKgy4AG"
   },
   "source": [
    "This function includes many convenient features, so the data is easy to work with. This includes:\n",
    "\n",
    "* Using the column headers as dictionary keys.\n",
    "* Automatically determining the type of each column.\n",
    "\n",
    "Caution: Make sure to set the `num_epochs` argument in `tf.data.experimental.make_csv_dataset`, otherwise the default behavior for `tf.data.Dataset` is to loop endlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:36.138703Z",
     "iopub.status.busy": "2022-06-17T01:24:36.138452Z",
     "iopub.status.idle": "2022-06-17T01:24:36.182894Z",
     "shell.execute_reply": "2022-06-17T01:24:36.182204Z"
    },
    "id": "v4oMO9MIxgTG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "months_as_customer  : [212 246 242 140 166]\n",
      "age                 : [35 43 40 30 37]\n",
      "policy_number       : [620855 805806 118137 521592 352120]\n",
      "policy_bind_date    : [b'1990-04-29' b'2013-01-16' b'1998-02-10' b'2014-06-15' b'1994-12-11']\n",
      "policy_state        : [b'IN' b'IN' b'OH' b'IL' b'IN']\n",
      "policy_csl          : [b'500/1000' b'250/500' b'100/300' b'100/300' b'250/500']\n",
      "policy_deductable   : [2000 1000  500  500  500]\n",
      "policy_annual_premium: [1123.89 1267.4  1238.65 1354.2  1518.54]\n",
      "umbrella_limit      : [      0 6000000       0       0       0]\n",
      "insured_zip         : [468313 454139 468702 438775 470510]\n",
      "insured_sex         : [b'MALE' b'MALE' b'FEMALE' b'FEMALE' b'FEMALE']\n",
      "insured_education_level: [b'MD' b'JD' b'High School' b'College' b'MD']\n",
      "insured_occupation  : [b'priv-house-serv' b'adm-clerical' b'transport-moving' b'adm-clerical'\n",
      " b'craft-repair']\n",
      "insured_hobbies     : [b'video-games' b'basketball' b'bungie-jumping' b'bungie-jumping'\n",
      " b'kayaking']\n",
      "insured_relationship: [b'unmarried' b'husband' b'husband' b'wife' b'not-in-family']\n",
      "capital-gains       : [ 35400      0      0 100500      0]\n",
      "capital-loss        : [-49200      0 -44600      0      0]\n",
      "incident_date       : [b'2015-01-21' b'2015-02-09' b'2015-01-27' b'2015-02-10' b'2015-01-25']\n",
      "incident_type       : [b'Multi-vehicle Collision' b'Single Vehicle Collision' b'Vehicle Theft'\n",
      " b'Multi-vehicle Collision' b'Single Vehicle Collision']\n",
      "collision_type      : [b'Front Collision' b'Side Collision' b'?' b'Side Collision'\n",
      " b'Rear Collision']\n",
      "incident_severity   : [b'Total Loss' b'Minor Damage' b'Trivial Damage' b'Minor Damage'\n",
      " b'Total Loss']\n",
      "authorities_contacted: [b'Fire' b'Fire' b'Police' b'Other' b'Ambulance']\n",
      "incident_state      : [b'NY' b'NY' b'WV' b'SC' b'PA']\n",
      "incident_city       : [b'Columbus' b'Hillsdale' b'Springfield' b'Columbus' b'Riverwood']\n",
      "incident_location   : [b'4119 Texas St' b'3771 4th St' b'9744 Texas Drive' b'2537 5th Ave'\n",
      " b'3726 MLK Hwy']\n",
      "incident_hour_of_the_day: [ 0  0  5  4 10]\n",
      "number_of_vehicles_involved: [3 1 1 4 1]\n",
      "property_damage     : [b'?' b'NO' b'YES' b'?' b'YES']\n",
      "bodily_injuries     : [1 2 1 0 1]\n",
      "witnesses           : [3 1 1 0 1]\n",
      "police_report_available: [b'?' b'?' b'NO' b'?' b'NO']\n",
      "total_claim_amount  : [50380 50700  7480 60170 58300]\n",
      "injury_claim        : [ 4580  5070   680  5470 10600]\n",
      "property_claim      : [ 4580  5070   680 10940 10600]\n",
      "vehicle_claim       : [41220 40560  6120 43760 37100]\n",
      "auto_make           : [b'Suburu' b'Accura' b'Saab' b'Nissan' b'Ford']\n",
      "auto_model          : [b'Forrestor' b'RSX' b'95' b'Pathfinder' b'F150']\n",
      "auto_year           : [1996 2006 1998 2006 2001]\n",
      "_c39                : [b'' b'' b'' b'' b'']\n",
      "\n",
      "label               : [b'N' b'N' b'N' b'N' b'N']\n"
     ]
    }
   ],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-TgA6o2Ja6U"
   },
   "source": [
    "Note: If you run the above cell twice it will produce different results. The default settings for `tf.data.experimental.make_csv_dataset` include `shuffle_buffer_size=1000`, which is more than sufficient for this small dataset, but may not be for a real-world dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6uviU_KCCWD"
   },
   "source": [
    "It can also decompress the data on the fly. Here's a gzipped CSV file containing the [metro interstate traffic dataset](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume).\n",
    "\n",
    "![A traffic jam.](images/csv/traffic.jpg)\n",
    "\n",
    "Image [from Wikimedia](https://commons.wikimedia.org/wiki/File:Trafficjam.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:36.186644Z",
     "iopub.status.busy": "2022-06-17T01:24:36.186073Z",
     "iopub.status.idle": "2022-06-17T01:24:36.847171Z",
     "shell.execute_reply": "2022-06-17T01:24:36.846536Z"
    },
    "id": "kT7oZI2E46Q8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  8192/405373 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 32768/405373 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 81920/405373 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "131072/405373 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "229376/405373 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "405373/405373 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-IOsFHbCw0i"
   },
   "source": [
    "Set the `compression_type` argument to read directly from the compressed file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:36.850870Z",
     "iopub.status.busy": "2022-06-17T01:24:36.850170Z",
     "iopub.status.idle": "2022-06-17T01:24:37.105142Z",
     "shell.execute_reply": "2022-06-17T01:24:37.104423Z"
    },
    "id": "ar0MPEVJ5NeA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday             : [b'None' b'None' b'None' b'None' b'None']\n",
      "temp                : [298.15 291.54 271.58 279.63 287.4 ]\n",
      "rain_1h             : [0.   0.   0.   0.   0.76]\n",
      "snow_1h             : [0. 0. 0. 0. 0.]\n",
      "clouds_all          : [ 0 40 64 40 92]\n",
      "weather_main        : [b'Clear' b'Clouds' b'Clouds' b'Clouds' b'Rain']\n",
      "weather_description : [b'Sky is Clear' b'scattered clouds' b'broken clouds' b'scattered clouds'\n",
      " b'light rain']\n",
      "date_time           : [b'2013-06-14 17:00:00' b'2013-06-01 00:00:00' b'2013-11-07 18:00:00'\n",
      " b'2012-11-21 17:00:00' b'2013-06-10 11:00:00']\n",
      "\n",
      "label               : [5508 1116 5773 4964 4688]\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type=\"GZIP\")\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value[:5]}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p12Y6tGq8D6M"
   },
   "source": [
    "Note: If you need to parse those date-time strings in the `tf.data` pipeline, you can use `tfa.text.parse_time`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtrAXzYGP3l0"
   },
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN2dL_LRP83r"
   },
   "source": [
    "There is some overhead to parsing the CSV data. For small models this can be the bottleneck in training.\n",
    "\n",
    "Depending on your use case, it may be a good idea to use `Dataset.cache` or `tf.data.experimental.snapshot`, so that the CSV data is only parsed on the first epoch.\n",
    "\n",
    "The main difference between the `cache` and `snapshot` methods is that `cache` files can only be used by the TensorFlow process that created them, but `snapshot` files can be read by other processes.\n",
    "\n",
    "For example, iterating over the `traffic_volume_csv_gz_ds` 20 times may take around 15 seconds without caching, or about two seconds with caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:37.109279Z",
     "iopub.status.busy": "2022-06-17T01:24:37.109047Z",
     "iopub.status.idle": "2022-06-17T01:24:47.192098Z",
     "shell.execute_reply": "2022-06-17T01:24:47.191383Z"
    },
    "id": "Qk38Sw4MO4eh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "CPU times: user 13.6 s, sys: 3.32 s, total: 16.9 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pN3HtDONh5TX"
   },
   "source": [
    "Note: `Dataset.cache` stores the data from the first epoch and replays it in order. So, using the `cache` method disables any shuffles earlier in the pipeline. Below, `Dataset.shuffle` is added back in after `Dataset.cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:47.195628Z",
     "iopub.status.busy": "2022-06-17T01:24:47.195352Z",
     "iopub.status.idle": "2022-06-17T01:24:48.456478Z",
     "shell.execute_reply": "2022-06-17T01:24:48.455850Z"
    },
    "id": "r5Jj72MrPbnh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........\n",
      "CPU times: user 1.4 s, sys: 180 ms, total: 1.58 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN7uUBjmgNZ9"
   },
   "source": [
    "Note: The `tf.data.experimental.snapshot` files are meant for *temporary* storage of a dataset while in use. This is *not* a format for long term storage. The file format is considered an internal detail, and not guaranteed between TensorFlow versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:48.459690Z",
     "iopub.status.busy": "2022-06-17T01:24:48.459421Z",
     "iopub.status.idle": "2022-06-17T01:24:50.113436Z",
     "shell.execute_reply": "2022-06-17T01:24:50.112495Z"
    },
    "id": "PHGD1E8ktUvW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <timed exec>:1: snapshot (from tensorflow.python.data.experimental.ops.snapshot) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.snapshot(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................\n",
      "CPU times: user 2.37 s, sys: 690 ms, total: 3.06 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snapshot = tf.data.experimental.snapshot('titanic.tfsnap')\n",
    "snapshotting = traffic_volume_csv_gz_ds.apply(snapshot).shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUSSegnMCGRz"
   },
   "source": [
    "If your data loading is slowed by loading CSV files, and `Dataset.cache` and `tf.data.experimental.snapshot` are insufficient for your use case, consider re-encoding your data into a more streamlined format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0iGXv9pC5kr"
   },
   "source": [
    "### Multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FFzHQrCDH4w"
   },
   "source": [
    "All the examples so far in this section could easily be done without `tf.data`. One place where `tf.data` can really simplify things is when dealing with collections of files.\n",
    "\n",
    "For example, the [character font images](https://archive.ics.uci.edu/ml/datasets/Character+Font+Images) dataset is distributed as a collection of csv files, one per font.\n",
    "\n",
    "![Fonts](images/csv/fonts.jpg)\n",
    "\n",
    "Image by <a href=\"https://pixabay.com/users/wilhei-883152/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=705667\">Willi Heidelbach</a> from <a href=\"https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=705667\">Pixabay</a>\n",
    "\n",
    "Download the dataset, and review the files inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:50.117182Z",
     "iopub.status.busy": "2022-06-17T01:24:50.116949Z",
     "iopub.status.idle": "2022-06-17T01:24:57.712666Z",
     "shell.execute_reply": "2022-06-17T01:24:57.711925Z"
    },
    "id": "RmVknMdJh5ks"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "     8192/160313983 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "    32768/160313983 [..............................] - ETA: 4:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "    81920/160313983 [..............................] - ETA: 3:17"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "   147456/160313983 [..............................] - ETA: 2:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "   303104/160313983 [..............................] - ETA: 1:46"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "   622592/160313983 [..............................] - ETA: 1:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "  1261568/160313983 [..............................] - ETA: 38s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "  2498560/160313983 [..............................] - ETA: 22s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "  4947968/160313983 [..............................] - ETA: 12s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "  8036352/160313983 [>.............................] - ETA: 8s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 11141120/160313983 [=>............................] - ETA: 6s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 14254080/160313983 [=>............................] - ETA: 5s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 17301504/160313983 [==>...........................] - ETA: 4s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 20430848/160313983 [==>...........................] - ETA: 4s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 23527424/160313983 [===>..........................] - ETA: 4s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 26517504/160313983 [===>..........................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 29605888/160313983 [====>.........................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 32727040/160313983 [=====>........................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 35799040/160313983 [=====>........................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 38895616/160313983 [======>.......................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 42024960/160313983 [======>.......................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 45137920/160313983 [=======>......................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 48250880/160313983 [========>.....................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 51306496/160313983 [========>.....................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 54411264/160313983 [=========>....................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 57532416/160313983 [=========>....................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 60628992/160313983 [==========>...................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 63758336/160313983 [==========>...................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 66854912/160313983 [===========>..................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 69861376/160313983 [============>.................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 72990720/160313983 [============>.................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 76087296/160313983 [=============>................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 79183872/160313983 [=============>................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 82190336/160313983 [==============>...............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 85286912/160313983 [==============>...............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 88350720/160313983 [===============>..............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 91447296/160313983 [================>.............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 94519296/160313983 [================>.............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 97427456/160313983 [=================>............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "100507648/160313983 [=================>............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "103251968/160313983 [==================>...........] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "106274816/160313983 [==================>...........] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "109002752/160313983 [===================>..........] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "112115712/160313983 [===================>..........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "115187712/160313983 [====================>.........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "117981184/160313983 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "121028608/160313983 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "123748352/160313983 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "126787584/160313983 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "129654784/160313983 [=======================>......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "132759552/160313983 [=======================>......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "135888896/160313983 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "139001856/160313983 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "142114816/160313983 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "145227776/160313983 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "148340736/160313983 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "151330816/160313983 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "154394624/160313983 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "157507584/160313983 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "160313983/160313983 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip',  \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_dir='.', cache_subdir='fonts',\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:57.716495Z",
     "iopub.status.busy": "2022-06-17T01:24:57.716264Z",
     "iopub.status.idle": "2022-06-17T01:24:57.721830Z",
     "shell.execute_reply": "2022-06-17T01:24:57.721311Z"
    },
    "id": "xsDlMCnyi55e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fonts/AGENCY.csv',\n",
       " 'fonts/ARIAL.csv',\n",
       " 'fonts/BAITI.csv',\n",
       " 'fonts/BANKGOTHIC.csv',\n",
       " 'fonts/BASKERVILLE.csv',\n",
       " 'fonts/BAUHAUS.csv',\n",
       " 'fonts/BELL.csv',\n",
       " 'fonts/BERLIN.csv',\n",
       " 'fonts/BERNARD.csv',\n",
       " 'fonts/BITSTREAMVERA.csv']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs =  sorted(str(p) for p in pathlib.Path('fonts').glob(\"*.csv\"))\n",
    "\n",
    "font_csvs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:57.724949Z",
     "iopub.status.busy": "2022-06-17T01:24:57.724424Z",
     "iopub.status.idle": "2022-06-17T01:24:57.728374Z",
     "shell.execute_reply": "2022-06-17T01:24:57.727847Z"
    },
    "id": "lRAEJx9ROAGl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(font_csvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19Udrw9iG-FS"
   },
   "source": [
    "When dealing with a bunch of files, you can pass a glob-style `file_pattern` to the `tf.data.experimental.make_csv_dataset` function. The order of the files is shuffled each iteration.\n",
    "\n",
    "Use the `num_parallel_reads` argument to set how many files are read in parallel and interleaved together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:57.731631Z",
     "iopub.status.busy": "2022-06-17T01:24:57.731178Z",
     "iopub.status.idle": "2022-06-17T01:24:58.433529Z",
     "shell.execute_reply": "2022-06-17T01:24:58.432745Z"
    },
    "id": "6TSUNdT6iG58"
   },
   "outputs": [],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMoexinLHYFa"
   },
   "source": [
    "These CSV files have the images flattened out into a single row. The column names are formatted `r{row}c{column}`. Here's the first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:24:58.437656Z",
     "iopub.status.busy": "2022-06-17T01:24:58.437418Z",
     "iopub.status.idle": "2022-06-17T01:25:00.548733Z",
     "shell.execute_reply": "2022-06-17T01:25:00.547860Z"
    },
    "id": "RmFvBWxxi3pq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font                : [b'NIRMALA' b'JAVANESE' b'JUICE' b'DUTCH801' b'LUCIDA' b'LUCIDA' b'JUICE'\n",
      " b'FREESTYLE' b'FREESTYLE' b'IMPRINT']\n",
      "fontVariant         : [b'NIRMALA UI SEMILIGHT' b'JAVANESE TEXT' b'JUICE ITC' b'DUTCH801 XBD BT'\n",
      " b'LUCIDA SANS UNICODE' b'LUCIDA SANS UNICODE' b'JUICE ITC'\n",
      " b'FREESTYLE SCRIPT' b'FREESTYLE SCRIPT' b'IMPRINT MT SHADOW']\n",
      "m_label             : [3521  213 8216  166 9653 9829  117 8482  711  111]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [0 1 1 1 0 0 1 0 1 0]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [53 44 30 38 59 39 45 32 44 53]\n",
      "m_left              : [24 30 35 29 27 24 26 29 46 22]\n",
      "originalH           : [40 61 12 58 18 48 36 27  6 30]\n",
      "originalW           : [56 47  8 28 22 48 29 41 10 30]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [  1   1   1   1   1   1   1   1 255   1]\n",
      "r0c1                : [  1   1   1   1   1   1   1   1 255   1]\n",
      "r0c2                : [  1   1   1   1   1  48   1   1 255   1]\n",
      "r0c3                : [ 55   1   1   1   1 176   1   7 255   1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "for features in fonts_ds.take(1):\n",
    "  for i, (name, value) in enumerate(features.items()):\n",
    "    if i>15:\n",
    "      break\n",
    "    print(f\"{name:20s}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrC3sKdeOhb5"
   },
   "source": [
    "#### Optional: Packing fields\n",
    "\n",
    "You probably don't want to work with each pixel in separate columns like this. Before trying to use this dataset be sure to pack the pixels into an image-tensor.\n",
    "\n",
    "Here is code that parses the column names to build images for each example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:00.552226Z",
     "iopub.status.busy": "2022-06-17T01:25:00.551982Z",
     "iopub.status.idle": "2022-06-17T01:25:00.556970Z",
     "shell.execute_reply": "2022-06-17T01:25:00.556451Z"
    },
    "id": "hct5EMEWNyfH"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def make_images(features):\n",
    "  image = [None]*400\n",
    "  new_feats = {}\n",
    "\n",
    "  for name, value in features.items():\n",
    "    match = re.match('r(\\d+)c(\\d+)', name)\n",
    "    if match:\n",
    "      image[int(match.group(1))*20+int(match.group(2))] = value\n",
    "    else:\n",
    "      new_feats[name] = value\n",
    "\n",
    "  image = tf.stack(image, axis=0)\n",
    "  image = tf.reshape(image, [20, 20, -1])\n",
    "  new_feats['image'] = image\n",
    "\n",
    "  return new_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61qy8utAwARP"
   },
   "source": [
    "Apply that function to each batch in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:00.560175Z",
     "iopub.status.busy": "2022-06-17T01:25:00.559756Z",
     "iopub.status.idle": "2022-06-17T01:25:02.982721Z",
     "shell.execute_reply": "2022-06-17T01:25:02.981891Z"
    },
    "id": "DJnnfIW9baE4"
   },
   "outputs": [],
   "source": [
    "fonts_image_ds = fonts_ds.map(make_images)\n",
    "\n",
    "for features in fonts_image_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ThqrthGwHSm"
   },
   "source": [
    "Plot the resulting images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:02.987959Z",
     "iopub.status.busy": "2022-06-17T01:25:02.987673Z",
     "iopub.status.idle": "2022-06-17T01:25:04.209759Z",
     "shell.execute_reply": "2022-06-17T01:25:04.209084Z"
    },
    "id": "I5dcey31T_tk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpfs/src/tf_docs_env/lib/python3.9/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 5532 (\\N{CANADIAN SYLLABICS WOODS-CREE THI}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6), dpi=120)\n",
    "\n",
    "for n in range(9):\n",
    "  plt.subplot(3,3,n+1)\n",
    "  plt.imshow(features['image'][..., n])\n",
    "  plt.title(chr(features['m_label'][n]))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-nNR0Nncdd1"
   },
   "source": [
    "## Lower level functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jiGZeUijJNd"
   },
   "source": [
    "So far this tutorial has focused on the highest-level utilities for reading csv data. There are other two APIs that may be helpful for advanced users if your use-case doesn't fit the basic patterns.\n",
    "\n",
    "* `tf.io.decode_csv`: a function for parsing lines of text into a list of CSV column tensors.\n",
    "* `tf.data.experimental.CsvDataset`: a lower-level CSV dataset constructor.\n",
    "\n",
    "This section recreates functionality provided by `tf.data.experimental.make_csv_dataset`, to demonstrate how this lower-level functionality can be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL_ixywomOHW"
   },
   "source": [
    "### `tf.io.decode_csv`\n",
    "\n",
    "This function decodes a string, or list of strings into a list of columns.\n",
    "\n",
    "Unlike `tf.data.experimental.make_csv_dataset` this function does not try to guess column data-types. You specify the column types by providing a list of `record_defaults` containing a value of the correct type, for each column.\n",
    "\n",
    "To read the Titanic data **as strings** using `tf.io.decode_csv` you would say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.214052Z",
     "iopub.status.busy": "2022-06-17T01:25:04.213482Z",
     "iopub.status.idle": "2022-06-17T01:25:04.218928Z",
     "shell.execute_reply": "2022-06-17T01:25:04.218391Z"
    },
    "id": "m1D2C-qdlqeW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pathlib.Path(titanic_file_path).read_text()\n",
    "lines = text.split('\\n')[1:-1]\n",
    "\n",
    "all_strings = [str()]*10\n",
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.221785Z",
     "iopub.status.busy": "2022-06-17T01:25:04.221550Z",
     "iopub.status.idle": "2022-06-17T01:25:04.227055Z",
     "shell.execute_reply": "2022-06-17T01:25:04.226513Z"
    },
    "id": "9W4UeJYyHPx5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=all_strings) \n",
    "\n",
    "for f in features:\n",
    "  print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8TaHSQFoQL4"
   },
   "source": [
    "To parse them with their actual types, create a list of `record_defaults` of the corresponding types: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.230023Z",
     "iopub.status.busy": "2022-06-17T01:25:04.229787Z",
     "iopub.status.idle": "2022-06-17T01:25:04.233273Z",
     "shell.execute_reply": "2022-06-17T01:25:04.232666Z"
    },
    "id": "rzUjR59yoUe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.236050Z",
     "iopub.status.busy": "2022-06-17T01:25:04.235796Z",
     "iopub.status.idle": "2022-06-17T01:25:04.240223Z",
     "shell.execute_reply": "2022-06-17T01:25:04.239684Z"
    },
    "id": "7sPTunxwoeWU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '', 0.0, 0, 0, 0.0, '', '', '', '']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\n",
    "titanic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.243034Z",
     "iopub.status.busy": "2022-06-17T01:25:04.242811Z",
     "iopub.status.idle": "2022-06-17T01:25:04.247865Z",
     "shell.execute_reply": "2022-06-17T01:25:04.247305Z"
    },
    "id": "n3NlViCzoB7F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: int32, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: float32, shape: (627,)\n",
      "type: int32, shape: (627,)\n",
      "type: int32, shape: (627,)\n",
      "type: float32, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=titanic_types) \n",
    "\n",
    "for f in features:\n",
    "  print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-LkTUTnpn2P"
   },
   "source": [
    "Note: It is more efficient to call `tf.io.decode_csv` on large batches of lines than on individual lines of CSV text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yp1UItJmqGqw"
   },
   "source": [
    "### `tf.data.experimental.CsvDataset`\n",
    "\n",
    "The `tf.data.experimental.CsvDataset` class provides a minimal CSV `Dataset` interface without the convenience features of the `tf.data.experimental.make_csv_dataset` function: column header parsing, column type-inference, automatic shuffling, file interleaving.\n",
    "\n",
    "This constructor uses `record_defaults` the same way as `tf.io.decode_csv`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.251120Z",
     "iopub.status.busy": "2022-06-17T01:25:04.250568Z",
     "iopub.status.idle": "2022-06-17T01:25:04.263310Z",
     "shell.execute_reply": "2022-06-17T01:25:04.262653Z"
    },
    "id": "9OzZLp3krP-t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "simple_titanic = tf.data.experimental.CsvDataset(titanic_file_path, record_defaults=titanic_types, header=True)\n",
    "\n",
    "for example in simple_titanic.take(1):\n",
    "  print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HBmfI-Ks7dw"
   },
   "source": [
    "The above code is basically equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.266355Z",
     "iopub.status.busy": "2022-06-17T01:25:04.265931Z",
     "iopub.status.idle": "2022-06-17T01:25:04.336037Z",
     "shell.execute_reply": "2022-06-17T01:25:04.335355Z"
    },
    "id": "E5O5d69Yq7gG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "def decode_titanic_line(line):\n",
    "  return tf.io.decode_csv(line, titanic_types)\n",
    "\n",
    "manual_titanic = (\n",
    "    # Load the lines of text\n",
    "    tf.data.TextLineDataset(titanic_file_path)\n",
    "    # Skip the header row.\n",
    "    .skip(1)\n",
    "    # Decode the line.\n",
    "    .map(decode_titanic_line)\n",
    ")\n",
    "\n",
    "for example in manual_titanic.take(1):\n",
    "  print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R3ralsnt2AC"
   },
   "source": [
    "#### Multiple files\n",
    "\n",
    "To parse the fonts dataset using `tf.data.experimental.CsvDataset`, you first need to determine the column types for the `record_defaults`. Start by inspecting the first row of one file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.339865Z",
     "iopub.status.busy": "2022-06-17T01:25:04.339265Z",
     "iopub.status.idle": "2022-06-17T01:25:04.347326Z",
     "shell.execute_reply": "2022-06-17T01:25:04.346645Z"
    },
    "id": "3tlFOTjCvAI5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENCY,AGENCY FB,64258,0.400000,0,0.000000,35,21,51,22,20,20,1,1,1,21,101,210,255,255,255,255,255,255,255,255,255,255,255,255,255,255,1,1,1,93,255,255,255,176,146,146,146,146,146,146,146,146,216,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,141,141,141,182,255,255,255,172,141,141,141,115,1,1,1,1,163,255,255,255,255,255,255,255,255,255,255,255,255,255,255,209,1,1,1,1,163,255,255,255,6,6,6,96,255,255,255,74,6,6,6,5,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255\n"
     ]
    }
   ],
   "source": [
    "font_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\n",
    "print(font_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etyGu8K_ySRz"
   },
   "source": [
    "Only the first two fields are strings, the rest are integers or floats, and you can get the total number of features by counting the commas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.350388Z",
     "iopub.status.busy": "2022-06-17T01:25:04.349931Z",
     "iopub.status.idle": "2022-06-17T01:25:04.353353Z",
     "shell.execute_reply": "2022-06-17T01:25:04.352741Z"
    },
    "id": "crgZZn0BzkSB"
   },
   "outputs": [],
   "source": [
    "num_font_features = font_line.count(',')+1\n",
    "font_column_types = [str(), str()] + [float()]*(num_font_features-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeK2Pw540RNj"
   },
   "source": [
    "The `tf.data.experimental.CsvDataset` constructor can take a list of input files, but reads them sequentially. The first file in the list of CSVs is `AGENCY.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.356707Z",
     "iopub.status.busy": "2022-06-17T01:25:04.356186Z",
     "iopub.status.idle": "2022-06-17T01:25:04.360122Z",
     "shell.execute_reply": "2022-06-17T01:25:04.359557Z"
    },
    "id": "_SvL5Uvl0r0N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fonts/AGENCY.csv'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_csvs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfAX3G8Xywy6"
   },
   "source": [
    "So, when you pass the list of files to `CsvDataset`, the records from `AGENCY.csv` are read first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.363243Z",
     "iopub.status.busy": "2022-06-17T01:25:04.362747Z",
     "iopub.status.idle": "2022-06-17T01:25:04.373041Z",
     "shell.execute_reply": "2022-06-17T01:25:04.372435Z"
    },
    "id": "Gtr1E66VmBqj"
   },
   "outputs": [],
   "source": [
    "simple_font_ds = tf.data.experimental.CsvDataset(\n",
    "    font_csvs, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.375987Z",
     "iopub.status.busy": "2022-06-17T01:25:04.375471Z",
     "iopub.status.idle": "2022-06-17T01:25:04.427634Z",
     "shell.execute_reply": "2022-06-17T01:25:04.426961Z"
    },
    "id": "k750Mgq4yt_o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n"
     ]
    }
   ],
   "source": [
    "for row in simple_font_ds.take(10):\n",
    "  print(row[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiqWKQV21FrE"
   },
   "source": [
    "To interleave multiple files, use `Dataset.interleave`.\n",
    "\n",
    "Here's an initial dataset that contains the CSV file names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.431000Z",
     "iopub.status.busy": "2022-06-17T01:25:04.430368Z",
     "iopub.status.idle": "2022-06-17T01:25:04.440057Z",
     "shell.execute_reply": "2022-06-17T01:25:04.439429Z"
    },
    "id": "t9dS3SNb23W8"
   },
   "outputs": [],
   "source": [
    "font_files = tf.data.Dataset.list_files(\"fonts/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNiLHMXpzHy5"
   },
   "source": [
    "This shuffles the file names each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.443478Z",
     "iopub.status.busy": "2022-06-17T01:25:04.442972Z",
     "iopub.status.idle": "2022-06-17T01:25:04.470790Z",
     "shell.execute_reply": "2022-06-17T01:25:04.470146Z"
    },
    "id": "zNd-TYyNzIgg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     b'fonts/TAHOMA.csv'\n",
      "     b'fonts/SCRIPTB.csv'\n",
      "     b'fonts/SIMPLEX.csv'\n",
      "     b'fonts/ONYX.csv'\n",
      "     b'fonts/PALATINO.csv'\n",
      "    ...\n",
      "\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     b'fonts/FREESTYLE.csv'\n",
      "     b'fonts/CORBEL.csv'\n",
      "     b'fonts/VLADIMIR.csv'\n",
      "     b'fonts/KRISTEN.csv'\n",
      "     b'fonts/SNAP.csv'\n",
      "    ...\n"
     ]
    }
   ],
   "source": [
    "print('Epoch 1:')\n",
    "for f in list(font_files)[:5]:\n",
    "  print(\"    \", f.numpy())\n",
    "print('    ...')\n",
    "print()\n",
    "\n",
    "print('Epoch 2:')\n",
    "for f in list(font_files)[:5]:\n",
    "  print(\"    \", f.numpy())\n",
    "print('    ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0QB1PtU3WAN"
   },
   "source": [
    "The `interleave` method takes a `map_func` that creates a child-`Dataset` for each element of the parent-`Dataset`.\n",
    "\n",
    "Here, you want to create a `tf.data.experimental.CsvDataset` from each element of the dataset of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.473782Z",
     "iopub.status.busy": "2022-06-17T01:25:04.473502Z",
     "iopub.status.idle": "2022-06-17T01:25:04.476954Z",
     "shell.execute_reply": "2022-06-17T01:25:04.476397Z"
    },
    "id": "QWp4rH0Q4uPh"
   },
   "outputs": [],
   "source": [
    "def make_font_csv_ds(path):\n",
    "  return tf.data.experimental.CsvDataset(\n",
    "    path, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxRGdLMB5nRF"
   },
   "source": [
    "The `Dataset` returned by interleave returns elements by cycling over a number of the child-`Dataset`s. Note, below, how the dataset cycles over `cycle_length=3` three font files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.479832Z",
     "iopub.status.busy": "2022-06-17T01:25:04.479560Z",
     "iopub.status.idle": "2022-06-17T01:25:04.663721Z",
     "shell.execute_reply": "2022-06-17T01:25:04.663129Z"
    },
    "id": "OePMNF_x1_Cc"
   },
   "outputs": [],
   "source": [
    "font_rows = font_files.interleave(make_font_csv_ds,\n",
    "                                  cycle_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.667450Z",
     "iopub.status.busy": "2022-06-17T01:25:04.667190Z",
     "iopub.status.idle": "2022-06-17T01:25:04.797539Z",
     "shell.execute_reply": "2022-06-17T01:25:04.796971Z"
    },
    "id": "UORIGWLy54-E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpfs/tmp/ipykernel_9839/998453860.py:5: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  fonts_dict['character'].append(chr(row[2].numpy()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>font_name</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATURA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAGE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MONOTYPE</td>\n",
       "      <td>ﬂ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MATURA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAGE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MONOTYPE</td>\n",
       "      <td>ﬁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MATURA</td>\n",
       "      <td>◊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RAGE</td>\n",
       "      <td>◊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MONOTYPE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MATURA</td>\n",
       "      <td>≥</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  font_name character\n",
       "0    MATURA         \n",
       "1      RAGE         \n",
       "2  MONOTYPE         ﬂ\n",
       "3    MATURA         \n",
       "4      RAGE         \n",
       "5  MONOTYPE         ﬁ\n",
       "6    MATURA         ◊\n",
       "7      RAGE         ◊\n",
       "8  MONOTYPE         \n",
       "9    MATURA         ≥"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fonts_dict = {'font_name':[], 'character':[]}\n",
    "\n",
    "for row in font_rows.take(10):\n",
    "  fonts_dict['font_name'].append(row[0].numpy().decode())\n",
    "  fonts_dict['character'].append(chr(row[2].numpy()))\n",
    "\n",
    "pd.DataFrame(fonts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkKZa_HX8zAm"
   },
   "source": [
    "#### Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BtGHraUApdJ"
   },
   "source": [
    "Earlier, it was noted that `tf.io.decode_csv` is more efficient when run on a batch of strings.\n",
    "\n",
    "It is possible to take advantage of this fact, when using large batch sizes, to improve CSV loading performance (but try [caching](#caching) first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d35zWMH7MDL1"
   },
   "source": [
    "With the built-in loader 20, 2048-example batches take about 17s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:04.803280Z",
     "iopub.status.busy": "2022-06-17T01:25:04.802736Z",
     "iopub.status.idle": "2022-06-17T01:25:05.514340Z",
     "shell.execute_reply": "2022-06-17T01:25:05.513671Z"
    },
    "id": "ieUVAPryjpJS"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=BATCH_SIZE, num_epochs=1,\n",
    "    num_parallel_reads=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:05.518224Z",
     "iopub.status.busy": "2022-06-17T01:25:05.517849Z",
     "iopub.status.idle": "2022-06-17T01:25:20.458838Z",
     "shell.execute_reply": "2022-06-17T01:25:20.458027Z"
    },
    "id": "MUC2KW4LkQIz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 34.9 s, sys: 4.82 s, total: 39.7 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_ds.take(20)):\n",
    "  print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lhnh6rZEDS2"
   },
   "source": [
    "Passing **batches of text lines** to`decode_csv` runs faster, in about 5s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:20.462428Z",
     "iopub.status.busy": "2022-06-17T01:25:20.461888Z",
     "iopub.status.idle": "2022-06-17T01:25:20.851111Z",
     "shell.execute_reply": "2022-06-17T01:25:20.850409Z"
    },
    "id": "4XbPZV1okVF9"
   },
   "outputs": [],
   "source": [
    "fonts_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n",
    "fonts_lines = fonts_files.interleave(\n",
    "    lambda fname:tf.data.TextLineDataset(fname).skip(1), \n",
    "    cycle_length=100).batch(BATCH_SIZE)\n",
    "\n",
    "fonts_fast = fonts_lines.map(lambda x: tf.io.decode_csv(x, record_defaults=font_column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T01:25:20.855589Z",
     "iopub.status.busy": "2022-06-17T01:25:20.854850Z",
     "iopub.status.idle": "2022-06-17T01:25:21.522272Z",
     "shell.execute_reply": "2022-06-17T01:25:21.521602Z"
    },
    "id": "te9C2km-qO8W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "CPU times: user 3.38 s, sys: 20.2 ms, total: 3.4 s\n",
      "Wall time: 663 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_fast.take(20)):\n",
    "  print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aebC1plsMeOi"
   },
   "source": [
    "For another example of increasing CSV performance by using large batches, refer to the [Overfit and underfit tutorial](../keras/overfit_and_underfit.ipynb).\n",
    "\n",
    "This sort of approach may work, but consider other options like `Dataset.cache` and `tf.data.experimental.snapshot`, or re-encoding your data into a more streamlined format."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "csv.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('testwebapps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8ed793b7e8cc3f131826b958c2ef0dc714f8054aba1686829c66364b88513ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
