{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USSV_OlCFKOD"
   },
   "source": [
    "# Training a neural network on MNIST with Keras\n",
    "\n",
    "This simple example demonstrates how to plug TensorFlow Datasets (TFDS) into a Keras model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8y9ZkLXmAZc"
   },
   "source": [
    "Copyright 2020 The TensorFlow Datasets Authors, Licensed under the Apache License, Version 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGw9EgE0tC0C"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/keras_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/datasets/blob/master/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/datasets/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-10T08:54:18.253377Z",
     "iopub.status.busy": "2022-02-10T08:54:18.252747Z",
     "iopub.status.idle": "2022-02-10T08:54:20.347380Z",
     "shell.execute_reply": "2022-02-10T08:54:20.346741Z"
    },
    "id": "TTBSvHcSLBzc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjI6VgOBf0v0"
   },
   "source": [
    "## Step 1: Create your input pipeline\n",
    "\n",
    "Start by building an efficient input pipeline using advices from:\n",
    "* The [Performance tips](https://www.tensorflow.org/datasets/performances) guide\n",
    "* The [Better performance with the `tf.data` API](https://www.tensorflow.org/guide/data_performance#optimize_performance) guide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3aH3vP_XLI8"
   },
   "source": [
    "### Load a dataset\n",
    "\n",
    "Load the MNIST dataset with the following arguments:\n",
    "\n",
    "* `shuffle_files=True`: The MNIST data is only stored in a single file, but for larger datasets with multiple files on disk, it's good practice to shuffle them when training.\n",
    "* `as_supervised=True`: Returns a tuple `(img, label)` instead of a dictionary `{'image': img, 'label': label}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-10T08:54:20.352400Z",
     "iopub.status.busy": "2022-02-10T08:54:20.351836Z",
     "iopub.status.idle": "2022-02-10T08:54:21.267974Z",
     "shell.execute_reply": "2022-02-10T08:54:21.268411Z"
    },
    "id": "ZUMhCXhFXdHQ"
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'imdb_reviews',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DPERALES\\OneDrive\\UST Global\\ITACA\\AI\\Tensorflow\\Beginners\\keras_example_dani.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Split the training set into 60% and 40% to end up with 15,000 examples\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# for training, 10,000 examples for validation and 25,000 examples for testing.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ds_train, ds_test, ds_info \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39mload(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimdb_reviews\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     split\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     shuffle_files\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     as_supervised\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     with_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# Split the training set into 60% and 40% to end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "ds_train, ds_test, ds_info = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgwCFAcWXQTx"
   },
   "source": [
    "### Build a training pipeline\n",
    "\n",
    "Apply the following transformations:\n",
    "\n",
    "* `tf.data.Dataset.map`: TFDS provide images of type `tf.uint8`, while the model expects `tf.float32`. Therefore, you need to normalize images.\n",
    "* `tf.data.Dataset.cache` As you fit the dataset in memory, cache it before shuffling for a better performance.<br/>\n",
    "__Note:__ Random transformations should be applied after caching.\n",
    "* `tf.data.Dataset.shuffle`: For true randomness, set the shuffle buffer to the full dataset size.<br/>\n",
    "__Note:__ For large datasets that can't fit in memory, use `buffer_size=1000` if your system allows it.\n",
    "* `tf.data.Dataset.batch`: Batch elements of the dataset after shuffling to get unique batches at each epoch.\n",
    "* `tf.data.Dataset.prefetch`: It is good practice to end the pipeline by prefetching [for performance](https://www.tensorflow.org/guide/data_performance#prefetching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-10T08:54:21.296628Z",
     "iopub.status.busy": "2022-02-10T08:54:21.274848Z",
     "iopub.status.idle": "2022-02-10T08:54:21.316234Z",
     "shell.execute_reply": "2022-02-10T08:54:21.315707Z"
    },
    "id": "haykx2K9XgiI"
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbsMy4X1XVFv"
   },
   "source": [
    "### Build an evaluation pipeline\n",
    "\n",
    "Your testing pipeline is similar to the training pipeline with small differences:\n",
    "\n",
    " * You don't need to call `tf.data.Dataset.shuffle`.\n",
    " * Caching is done after batching because batches can be the same between epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-10T08:54:21.321408Z",
     "iopub.status.busy": "2022-02-10T08:54:21.320618Z",
     "iopub.status.idle": "2022-02-10T08:54:21.329812Z",
     "shell.execute_reply": "2022-02-10T08:54:21.330226Z"
    },
    "id": "A0KjuDf7XiqY"
   },
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTFoji3INMEM"
   },
   "source": [
    "## Step 2: Create and train the model\n",
    "\n",
    "Plug the TFDS input pipeline into a simple Keras model, compile the model, and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-10T08:54:21.335980Z",
     "iopub.status.busy": "2022-02-10T08:54:21.335374Z",
     "iopub.status.idle": "2022-02-10T08:54:31.025315Z",
     "shell.execute_reply": "2022-02-10T08:54:31.025776Z"
    },
    "id": "XWqxdmS1NLKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_8_input'), name='flatten_8_input', description=\"created by layer 'flatten_8_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_8_input'), name='flatten_8_input', description=\"created by layer 'flatten_8_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_6\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_15\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_6\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DPERALES\\OneDrive\\UST Global\\ITACA\\AI\\Tensorflow\\Beginners\\keras_example_dani.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(input_shape\u001b[39m=\u001b[39m(\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m)),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m10\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(\u001b[39m0.001\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mSparseCategoricalAccuracy()],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     ds_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mds_test,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DPERALES/OneDrive/UST%20Global/ITACA/AI/Tensorflow/Beginners/keras_example_dani.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filekopl8yss.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\DPERALES\\Anaconda3\\envs\\testwebapps\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_6\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_15\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_6\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tensorflow/datasets",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('testwebapps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8ed793b7e8cc3f131826b958c2ef0dc714f8054aba1686829c66364b88513ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
